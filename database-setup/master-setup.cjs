// Master Database Setup Script
// Runs all 20 database tasks in the correct order for complete platform setup

require('dotenv').config({ path: '../.env' })
const { createClient } = require('@supabase/supabase-js')
const fs = require('fs')
const path = require('path')

class MasterDatabaseSetup {
  constructor() {
    this.supabase = createClient(
      process.env.NEXT_PUBLIC_SUPABASE_URL,
      process.env.SUPABASE_SERVICE_ROLE_KEY
    )
    
    this.setupTasks = [
      // Core Infrastructure Setup
      {
        id: 1,
        name: 'Supabase Advanced Configuration',
        files: ['01-supabase-advanced-config-fixed.sql'],
        description: 'Configure PostgreSQL extensions, RLS, connection pooling, and performance optimization'
      },
      {
        id: 2,
        name: 'Security Foundation',
        files: ['02-security-foundation.sql'],
        description: 'Implement comprehensive RLS policies, audit logging, encryption, and security monitoring'
      },
      
      // Community & User Management
      {
        id: 3,
        name: 'Community Management System',
        files: ['03-community-management-simple.sql'],
        description: 'Create community management with data sovereignty and governance features'
      },
      {
        id: 4,
        name: 'Advanced User Management',
        files: ['04-advanced-user-management-simple.sql'],
        description: 'Build RBAC system, cultural preferences, and user verification flows'
      },
      
      // Document Storage & Processing
      {
        id: 5,
        name: 'Document Storage System',
        files: ['05-document-storage-system-minimal.sql'],
        description: 'Create scalable document storage with cultural sensitivity classification'
      },
      {
        id: 6,
        name: 'Document Chunking System',
        files: [
          'task-6-step-1-document-chunks.sql',
          'task-6-step-2-chunking-algorithms.sql',
          'task-6-step-3-test-chunking.sql',
          'task-6-step-4-chunk-security.sql'
        ],
        description: 'Implement document chunking with vector embeddings and semantic search'
      },
      
      // AI Analysis & Insights
      {
        id: 7,
        name: 'AI Analysis Results Storage',
        files: [
          'task-7-step-1-document-themes.sql',
          'task-7-step-2-document-quotes.sql',
          'task-7-step-3-ai-model-tracking.sql',
          'task-7-step-4-ai-analysis-functions.sql',
          'task-7-step-5-test-ai-analysis.sql',
          'task-7-step-6-rls-and-completion.sql'
        ],
        description: 'Create AI analysis storage with cultural sensitivity and provenance tracking'
      },
      {
        id: 8,
        name: 'Advanced Search Capabilities',
        files: [
          'task-8-step-1-fulltext-search.sql',
          'task-8-step-2-faceted-search.sql',
          'task-8-step-3-search-analytics.sql',
          'task-8-step-4-test-search-system.sql'
        ],
        description: 'Build full-text search, vector similarity search, and search analytics'
      },
      
      // Collections & Research Management
      {
        id: 9,
        name: 'Research Collections System',
        files: [
          'task-9-step-1-research-collections.sql',
          'task-9-step-2-collection-functions.sql',
          'task-9-step-3-test-research-system.sql'
        ],
        description: 'Implement research collections with collaborative features and permissions'
      },
      {
        id: 10,
        name: 'Real-time Collaboration Features',
        files: [
          'task-10-step-1-realtime-activity.sql',
          'task-10-step-2-collaborative-editing.sql',
          'task-10-step-3-test-collaboration.sql'
        ],
        description: 'Build real-time collaboration with cultural protocol enforcement'
      },
      
      // Performance & Scalability
      {
        id: 11,
        name: 'Database Performance Optimization',
        files: [
          'task-11-step-1-indexing-strategy.sql',
          'task-11-step-2-materialized-views.sql'
        ],
        description: 'Implement comprehensive indexing and materialized views for analytics'
      },
      {
        id: 12,
        name: 'Horizontal Scaling Infrastructure',
        files: [
          'task-12-step-2-connection-pooling.sql',
          'task-12-step-3-replication-setup.sql',
          'task-12-step-4-test-scaling.sql'
        ],
        description: 'Configure read replicas, connection pooling, and automatic scaling'
      },
      
      // Monitoring & Maintenance
      {
        id: 13,
        name: 'Comprehensive Monitoring System',
        files: [
          'task-13-step-1-monitoring-system.sql',
          'task-13-step-2-performance-monitoring.sql',
          'task-13-step-3-test-monitoring.sql'
        ],
        description: 'Build database performance monitoring and alerting systems'
      },
      {
        id: 14,
        name: 'Backup and Disaster Recovery',
        files: [
          'task-14-step-1-backup-system.sql',
          'task-14-step-2-backup-integrity.sql',
          'task-14-step-3-test-backup-system.sql'
        ],
        description: 'Implement automated backups with cultural data protection'
      },
      
      // Migration & Integration
      {
        id: 15,
        name: 'Database Migration System',
        files: [
          'task-15-step-1-migration-system.sql',
          'task-15-step-2-zero-downtime-migrations.sql',
          'task-15-step-3-test-migration-system.sql'
        ],
        description: 'Create schema versioning and zero-downtime migration tools'
      },
      {
        id: 16,
        name: 'API and Integration Layer',
        files: [
          'task-16-step-1-api-layer.sql',
          'task-16-step-2-graphql-rest-api.sql',
          'task-16-step-3-test-api-integration.sql'
        ],
        description: 'Build secure GraphQL/REST APIs with cultural protocol integration'
      },
      
      // Testing & Quality Assurance
      {
        id: 17,
        name: 'Comprehensive Testing Suite',
        files: [
          'task-17-step-1-testing-framework.sql',
          'task-17-step-2-database-function-tests.sql',
          'task-17-step-3-execute-test-suite.sql'
        ],
        description: 'Implement database testing framework with cultural sensitivity scenarios'
      },
      {
        id: 18,
        name: 'Data Quality and Validation System',
        files: [
          'task-18-step-1-data-quality-framework.sql',
          'task-18-step-2-validation-rules.sql',
          'task-18-step-3-test-data-quality.sql'
        ],
        description: 'Build data integrity checks and cultural governance reporting'
      },
      
      // Documentation & Training
      {
        id: 19,
        name: 'Comprehensive Documentation',
        files: [
          'task-19-step-1-schema-documentation.sql',
          'task-19-step-2-api-documentation.sql',
          'task-19-step-3-admin-guides.sql',
          'task-19-step-4-developer-onboarding.sql',
          'task-19-step-5-community-user-guides.sql'
        ],
        description: 'Create complete documentation with cultural context and community approval'
      },
      {
        id: 20,
        name: 'Final System Validation',
        files: [
          'task-20-step-1-end-to-end-testing.sql',
          'task-20-step-2-security-penetration-testing.sql',
          'task-20-step-3-performance-benchmarking.sql',
          'task-20-step-4-cultural-protocol-validation.sql',
          'task-20-step-5-production-readiness-checklist.sql'
        ],
        description: 'Complete system validation with community approval and production readiness'
      }
    ]

    this.results = {
      completed: [],
      failed: [],
      skipped: []
    }
  }

  async validateEnvironment() {
    console.log('ğŸ” Validating environment before setup...\n')

    try {
      const { data, error } = await this.supabase
        .from('information_schema.schemata')
        .select('schema_name')
        .limit(1)

      if (error) {
        console.error('âŒ Database connection failed:', error.message)
        return false
      }

      console.log('âœ… Database connection successful')
      return true
    } catch (error) {
      console.error('âŒ Environment validation failed:', error.message)
      return false
    }
  }

  async executeSQL(sqlContent, taskName) {
    try {
      // Split SQL content by semicolons and execute each statement
      const statements = sqlContent
        .split(';')
        .map(stmt => stmt.trim())
        .filter(stmt => stmt.length > 0 && !stmt.startsWith('--'))

      for (const statement of statements) {
        if (statement.trim()) {
          const { error } = await this.supabase.rpc('exec_sql', { 
            sql_query: statement 
          })
          
          if (error && !this.isIgnorableError(error)) {
            throw error
          }
        }
      }

      return { success: true }
    } catch (error) {
      // Try alternative execution method
      try {
        const { error: directError } = await this.supabase
          .from('pg_stat_statements')
          .select('query')
          .limit(1)

        // If we can access pg_stat_statements, we have sufficient privileges
        // Execute using raw SQL
        const { data, error } = await this.supabase.rpc('execute_sql_batch', {
          sql_content: sqlContent
        })

        if (error && !this.isIgnorableError(error)) {
          throw error
        }

        return { success: true }
      } catch (fallbackError) {
        return { 
          success: false, 
          error: error.message || fallbackError.message 
        }
      }
    }
  }

  isIgnorableError(error) {
    const ignorableMessages = [
      'already exists',
      'does not exist',
      'permission denied',
      'relation already exists',
      'function already exists',
      'type already exists'
    ]

    return ignorableMessages.some(msg => 
      error.message.toLowerCase().includes(msg.toLowerCase())
    )
  }

  async executeTask(task) {
    console.log(`\nğŸ“‹ Task ${task.id}: ${task.name}`)
    console.log(`ğŸ“ ${task.description}`)
    console.log('â”€'.repeat(80))

    const taskStartTime = Date.now()
    let allFilesSucceeded = true
    const fileResults = []

    for (const filename of task.files) {
      const filePath = path.join(__dirname, filename)
      
      if (!fs.existsSync(filePath)) {
        console.log(`âš ï¸  File not found: ${filename} - skipping`)
        fileResults.push({ filename, status: 'skipped', reason: 'file not found' })
        continue
      }

      console.log(`   ğŸ”„ Executing: ${filename}`)
      
      try {
        const sqlContent = fs.readFileSync(filePath, 'utf8')
        const result = await this.executeSQL(sqlContent, `${task.name} - ${filename}`)

        if (result.success) {
          console.log(`   âœ… ${filename} completed successfully`)
          fileResults.push({ filename, status: 'success' })
        } else {
          console.log(`   âŒ ${filename} failed: ${result.error}`)
          fileResults.push({ filename, status: 'failed', error: result.error })
          allFilesSucceeded = false
        }
      } catch (error) {
        console.log(`   âŒ ${filename} failed: ${error.message}`)
        fileResults.push({ filename, status: 'failed', error: error.message })
        allFilesSucceeded = false
      }

      // Brief pause between files
      await new Promise(resolve => setTimeout(resolve, 1000))
    }

    const taskDuration = Date.now() - taskStartTime
    const taskResult = {
      id: task.id,
      name: task.name,
      duration: taskDuration,
      success: allFilesSucceeded,
      fileResults
    }

    if (allFilesSucceeded) {
      console.log(`âœ… Task ${task.id} completed successfully (${(taskDuration / 1000).toFixed(1)}s)`)
      this.results.completed.push(taskResult)
    } else {
      console.log(`âŒ Task ${task.id} completed with errors (${(taskDuration / 1000).toFixed(1)}s)`)
      this.results.failed.push(taskResult)
    }

    return taskResult
  }

  async runAllTasks() {
    console.log('ğŸš€ Starting Barkly Research Platform Database Setup')
    console.log('=' .repeat(80))
    console.log('This will set up your complete database schema with cultural protocols')
    console.log('Estimated time: 15-20 minutes\n')

    const overallStartTime = Date.now()

    // Environment validation
    const envValid = await this.validateEnvironment()
    if (!envValid) {
      console.log('âŒ Environment validation failed. Exiting.')
      process.exit(1)
    }

    // Execute each task
    for (const task of this.setupTasks) {
      await this.executeTask(task)
      
      // Brief pause between tasks
      await new Promise(resolve => setTimeout(resolve, 2000))
    }

    const overallDuration = Date.now() - overallStartTime
    this.generateFinalReport(overallDuration)
  }

  generateFinalReport(overallDuration) {
    console.log('\n' + '='.repeat(80))
    console.log('ğŸ“Š DATABASE SETUP COMPLETION REPORT')
    console.log('='.repeat(80))

    console.log(`\nğŸ“ˆ Overall Results:`)
    console.log(`   âœ… Completed: ${this.results.completed.length}`)
    console.log(`   âŒ Failed: ${this.results.failed.length}`)
    console.log(`   â±ï¸  Total Time: ${(overallDuration / 1000 / 60).toFixed(1)} minutes`)

    console.log(`\nğŸ“‹ Task Details:`)
    this.setupTasks.forEach(task => {
      const result = [...this.results.completed, ...this.results.failed]
        .find(r => r.id === task.id)
      
      if (result) {
        const status = result.success ? 'âœ…' : 'âŒ'
        console.log(`   ${status} Task ${task.id}: ${task.name} (${(result.duration / 1000).toFixed(1)}s)`)
      } else {
        console.log(`   â¸ï¸  Task ${task.id}: ${task.name} (not executed)`)
      }
    })

    // Failed tasks details
    if (this.results.failed.length > 0) {
      console.log(`\nâŒ FAILED TASKS (${this.results.failed.length}):`)
      this.results.failed.forEach(task => {
        console.log(`\n   Task ${task.id}: ${task.name}`)
        task.fileResults.forEach(file => {
          if (file.status === 'failed') {
            console.log(`     âŒ ${file.filename}: ${file.error}`)
          }
        })
      })
    }

    // Success assessment
    console.log('\nğŸ¯ SETUP ASSESSMENT:')
    if (this.results.failed.length === 0) {
      console.log('   âœ… All tasks completed successfully!')
      console.log('   âœ… Database schema fully configured')
      console.log('   âœ… Cultural protocols implemented')
      console.log('   âœ… Security measures in place')
      console.log('   âœ… Performance optimizations applied')
      console.log('   âœ… Ready for comprehensive testing!')
    } else if (this.results.failed.length <= 2) {
      console.log('   âš ï¸  Setup mostly successful with minor issues')
      console.log('   âœ… Core functionality should be working')
      console.log('   ğŸ”§ Review failed tasks and address if needed')
    } else {
      console.log('   âŒ Multiple setup failures detected')
      console.log('   ğŸ”§ Review and fix failed tasks before proceeding')
    }

    console.log('\nğŸ“‹ NEXT STEPS:')
    if (this.results.failed.length === 0) {
      console.log('   1. Run the comprehensive test suite: npm test')
      console.log('   2. Validate all systems are working correctly')
      console.log('   3. Conduct community validation of cultural protocols')
      console.log('   4. Prepare for production deployment!')
    } else {
      console.log('   1. Review failed task details above')
      console.log('   2. Check Supabase logs for additional error information')
      console.log('   3. Re-run individual failed tasks if needed')
      console.log('   4. Run test suite to validate working components')
    }

    console.log('\n' + '='.repeat(80))
    console.log('ğŸ Database setup completed!')
    console.log('='.repeat(80))
  }
}

// Run setup if this file is executed directly
if (require.main === module) {
  const setup = new MasterDatabaseSetup()
  setup.runAllTasks().catch(error => {
    console.error('ğŸ’¥ Database setup failed:', error)
    process.exit(1)
  })
}

module.exports = MasterDatabaseSetup